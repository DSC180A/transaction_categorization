{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28146e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f8e0dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>amount</th>\n",
       "      <th>memo</th>\n",
       "      <th>new_category</th>\n",
       "      <th>Cleaned Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-03-06</td>\n",
       "      <td>15.25</td>\n",
       "      <td>POS CASINO BAR @ SPOTL - MEMO=PURCHASE 03/02 C...</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>pos casino bar spotl memopurchase 0302 coache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2018-09-29</td>\n",
       "      <td>16.04</td>\n",
       "      <td>BEST BUY   GRAND REGENCY BRANDON F</td>\n",
       "      <td>General Merchandise</td>\n",
       "      <td>best buy grand regency brandon f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>10.36</td>\n",
       "      <td>CORNER STORE  ARLINGTON TX 10/17 Purchase $5.3...</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>corner store arlington tx 1017 purchase $536 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2017-07-11</td>\n",
       "      <td>4.63</td>\n",
       "      <td>SPEEDWAY  IN BEDFORD IN 07/10 DEBIT_CARD</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>speedway bedford 0710 debitcard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2018-09-10</td>\n",
       "      <td>223.00</td>\n",
       "      <td>PAYMENT FOR AMZ STORECARD  WEB ID:  ACH_DEBIT</td>\n",
       "      <td>General Merchandise</td>\n",
       "      <td>payment amz storecard web id achdebit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999981</th>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>24.24</td>\n",
       "      <td>DBT/WDR CASEYS GEN STORE  FENNIMORE WI</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>dbtwdr caseys gen store fennimore wi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999982</th>\n",
       "      <td>2021-01-19</td>\n",
       "      <td>120.60</td>\n",
       "      <td>POS Debit - DDA KOHLS  CLIVE IA #</td>\n",
       "      <td>General Merchandise</td>\n",
       "      <td>pos debit dda kohls clive ia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999983</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>6.47</td>\n",
       "      <td>STARBUCKS STORE  MAPLE VALLEY WA        02/24</td>\n",
       "      <td>Food and Beverages</td>\n",
       "      <td>starbucks store maple valley wa 0224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999991</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>44.98</td>\n",
       "      <td>POS Debit - Visa Check Card  - APPLE.COM/BILL ...</td>\n",
       "      <td>General Merchandise</td>\n",
       "      <td>pos debit visa check card applecombill ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999992</th>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NAYAX VENDING 2 HUNT VALLEY MD               0...</td>\n",
       "      <td>Food and Beverages</td>\n",
       "      <td>nayax vending 2 hunt valley md 0409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496101 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        transaction_date  amount  \\\n",
       "8             2018-03-06   15.25   \n",
       "39            2018-09-29   16.04   \n",
       "45            2018-10-17   10.36   \n",
       "52            2017-07-11    4.63   \n",
       "55            2018-09-10  223.00   \n",
       "...                  ...     ...   \n",
       "1999981       2021-02-19   24.24   \n",
       "1999982       2021-01-19  120.60   \n",
       "1999983       2022-02-25    6.47   \n",
       "1999991       2021-01-11   44.98   \n",
       "1999992       2022-04-11    1.00   \n",
       "\n",
       "                                                      memo  \\\n",
       "8        POS CASINO BAR @ SPOTL - MEMO=PURCHASE 03/02 C...   \n",
       "39                      BEST BUY   GRAND REGENCY BRANDON F   \n",
       "45       CORNER STORE  ARLINGTON TX 10/17 Purchase $5.3...   \n",
       "52                SPEEDWAY  IN BEDFORD IN 07/10 DEBIT_CARD   \n",
       "55           PAYMENT FOR AMZ STORECARD  WEB ID:  ACH_DEBIT   \n",
       "...                                                    ...   \n",
       "1999981             DBT/WDR CASEYS GEN STORE  FENNIMORE WI   \n",
       "1999982                  POS Debit - DDA KOHLS  CLIVE IA #   \n",
       "1999983      STARBUCKS STORE  MAPLE VALLEY WA        02/24   \n",
       "1999991  POS Debit - Visa Check Card  - APPLE.COM/BILL ...   \n",
       "1999992  NAYAX VENDING 2 HUNT VALLEY MD               0...   \n",
       "\n",
       "                new_category  \\\n",
       "8              Entertainment   \n",
       "39       General Merchandise   \n",
       "45                Automotive   \n",
       "52                Automotive   \n",
       "55       General Merchandise   \n",
       "...                      ...   \n",
       "1999981           Automotive   \n",
       "1999982  General Merchandise   \n",
       "1999983   Food and Beverages   \n",
       "1999991  General Merchandise   \n",
       "1999992   Food and Beverages   \n",
       "\n",
       "                                              Cleaned Text  \n",
       "8         pos casino bar spotl memopurchase 0302 coache...  \n",
       "39                        best buy grand regency brandon f  \n",
       "45        corner store arlington tx 1017 purchase $536 ...  \n",
       "52                         speedway bedford 0710 debitcard  \n",
       "55                   payment amz storecard web id achdebit  \n",
       "...                                                    ...  \n",
       "1999981               dbtwdr caseys gen store fennimore wi  \n",
       "1999982                       pos debit dda kohls clive ia  \n",
       "1999983               starbucks store maple valley wa 0224  \n",
       "1999991          pos debit visa check card applecombill ca  \n",
       "1999992                nayax vending 2 hunt valley md 0409  \n",
       "\n",
       "[496101 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_parquet(\"../data/df_cleaned.parquet\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "008ed9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Food and Beverages     0.326565\n",
       "General Merchandise    0.280126\n",
       "Automotive             0.128234\n",
       "Groceries              0.128081\n",
       "Entertainment          0.063479\n",
       "Travel                 0.051383\n",
       "Healthcare/Medical     0.016916\n",
       "Pets/Pet Care          0.005217\n",
       "Name: new_category, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['new_category'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929dc7ca",
   "metadata": {},
   "source": [
    "# Part 1: TF-IDF Model\n",
    "\n",
    "##### Koosha's TF-IDF model + Nathan's fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19d862e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the feature columns\n",
    "feature_columns = \"Cleaned Text\"\n",
    "\n",
    "# define the target column\n",
    "target_column = \"new_category\"\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target column\n",
    "y = le.fit_transform(data[target_column])\n",
    "\n",
    "# create the feature matrix and target vector\n",
    "X = data[feature_columns]\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ba02921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['Automotive']\n",
      "1 ['Entertainment']\n",
      "2 ['Food and Beverages']\n",
      "3 ['General Merchandise']\n",
      "4 ['Groceries']\n",
      "5 ['Healthcare/Medical']\n",
      "6 ['Pets/Pet Care']\n",
      "7 ['Travel']\n"
     ]
    }
   ],
   "source": [
    "# le.classes_\n",
    "for i in range(8):\n",
    "    print(i, le.inverse_transform([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b27d965c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", vectorizer),\n",
    "    (\"classifier\", LogisticRegression())\n",
    "])\n",
    "\n",
    "# fit the model on the training data\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b725bd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category: ['Automotive']\n"
     ]
    }
   ],
   "source": [
    "# test the model on the test data\n",
    "test_data = \"autozone\"\n",
    "predicted_category = pipeline.predict([test_data])\n",
    "\n",
    "print(\"Predicted category:\", le.inverse_transform(predicted_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9bc7181c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.8560599582198224\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test data\n",
    "score = pipeline.score(X_test, y_test)\n",
    "print(\"Test score:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4492e0b2",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4061f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestTFIDF(gram='word', ngram_range=(1,1)):\n",
    "        # create the TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(analyzer=gram, ngram_range=ngram_range)\n",
    "\n",
    "    # create the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        (\"vectorizer\", vectorizer),\n",
    "        (\"classifier\", LogisticRegression())\n",
    "    ])\n",
    "\n",
    "    # fit the model on the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # evaluate the model on the test data\n",
    "    score = pipeline.score(X_test, y_test)\n",
    "    print(\"Test score:\", score)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1e10e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.8746594671194888\n"
     ]
    }
   ],
   "source": [
    "# trainTestTFIDF('word')\n",
    "# trainTestTFIDF('word', ngram_range=(2,2)) # bigrams\n",
    "# trainTestTFIDF('word', ngram_range=(3,3)) # trigrams\n",
    "# trainTestTFIDF('char')\n",
    "# trainTestTFIDF('char', ngram_range=(2,2))\n",
    "# trainTestTFIDF('char', ngram_range=(3,3))\n",
    "# trainTestTFIDF('char', ngram_range=(4,4))\n",
    "\n",
    "best_tfidf = trainTestTFIDF('char', ngram_range=(5,5)) # BEST\n",
    "#  '123 4567' includes: '123 4', '23 45', '3 456', ' 4567'\n",
    "\n",
    "# trainTestTFIDF('char', ngram_range=(6,6))\n",
    "# trainTestTFIDF('char', ngram_range=(7,7))\n",
    "# trainTestTFIDF('char', ngram_range=(8,8))\n",
    "\n",
    "tfidf_proba = best_tfidf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd006e0c",
   "metadata": {},
   "source": [
    "# Part 2: Non-Text Model\n",
    "##### Kyle's Non-Text Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d6852f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>dt</th>\n",
       "      <th>new_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.25</td>\n",
       "      <td>2018-03-06</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>16.04</td>\n",
       "      <td>2018-09-29</td>\n",
       "      <td>General Merchandise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10.36</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4.63</td>\n",
       "      <td>2017-07-11</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>223.00</td>\n",
       "      <td>2018-09-10</td>\n",
       "      <td>General Merchandise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999981</th>\n",
       "      <td>24.24</td>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999982</th>\n",
       "      <td>120.60</td>\n",
       "      <td>2021-01-19</td>\n",
       "      <td>General Merchandise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999983</th>\n",
       "      <td>6.47</td>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>Food and Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999991</th>\n",
       "      <td>44.98</td>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>General Merchandise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999992</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>Food and Beverages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         amount         dt         new_category\n",
       "8         15.25 2018-03-06        Entertainment\n",
       "39        16.04 2018-09-29  General Merchandise\n",
       "45        10.36 2018-10-17           Automotive\n",
       "52         4.63 2017-07-11           Automotive\n",
       "55       223.00 2018-09-10  General Merchandise\n",
       "...         ...        ...                  ...\n",
       "1999981   24.24 2021-02-19           Automotive\n",
       "1999982  120.60 2021-01-19  General Merchandise\n",
       "1999983    6.47 2022-02-25   Food and Beverages\n",
       "1999991   44.98 2021-01-11  General Merchandise\n",
       "1999992    1.00 2022-04-11   Food and Beverages\n",
       "\n",
       "[496101 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['dt'] = pd.to_datetime(data['transaction_date'])\n",
    "data = data[[\"amount\", \"dt\", \"new_category\"]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfe44318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering using dt column: adding year, month, day, etc.\n",
    "data['year'] = data['dt'].dt.year # ranges 2010 - 2022\n",
    "data['month'] = data['dt'].dt.month # ranges 1 - 12\n",
    "data['is_holiday'] = data['month'].apply(lambda x: 1 if x == 11 or x == 12 else 0) # 0 or 1\n",
    "data['day'] = data['dt'].dt.dayofweek # to be discarded\n",
    "data['is_weekend'] = data['day'].apply(lambda x: 1 if x == 5 or x == 6 else 0) # 0 or 1\n",
    "\n",
    "# feature engineering using amount: encoding whole numbers\n",
    "data['is_whole_number'] = data['amount'].apply(lambda x: 1 if str(x).split(\".\")[1] == \"0\" else 0)\n",
    "data\n",
    "\n",
    "# X y split\n",
    "X = data[[\"amount\", \"is_whole_number\", \"year\", \"month\", \"day\", \"is_holiday\", \"is_weekend\"]]\n",
    "y = data[[\"new_category\"]]\n",
    "\n",
    "# standard scale: amount\n",
    "scaler = StandardScaler()\n",
    "scaler_df = pd.DataFrame(scaler.fit_transform(X[['amount']]), index = X.index)\n",
    "\n",
    "# one hot encode: year, month, day\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder_df = pd.DataFrame(ohe.fit_transform(X[['year']]).toarray(), columns = pd.Series(X['year'].unique()).sort_values().values, index = X.index)\n",
    "\n",
    "ohe2 = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder_df2 = pd.DataFrame(ohe2.fit_transform(X[['month']]).toarray(), columns = pd.Series(X['month'].unique()).sort_values().values, index = X.index)\n",
    "\n",
    "# monday = 0, sunday = 6\n",
    "def convert_date_to_day(date):\n",
    "    if date == 0:\n",
    "        return \"monday\"\n",
    "    if date == 1:\n",
    "        return \"tuesday\"\n",
    "    if date == 2:\n",
    "        return \"wednesday\"\n",
    "    if date == 3:\n",
    "        return \"thursday\"\n",
    "    if date == 4:\n",
    "        return \"friday\"\n",
    "    if date == 5:\n",
    "        return \"saturday\"\n",
    "    if date == 6:\n",
    "        return \"sunday\"\n",
    "\n",
    "X['day_word'] = X['day'].apply(convert_date_to_day)\n",
    "ohe3 = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder_df3 = pd.DataFrame(ohe3.fit_transform(X[['day_word']]).toarray(), columns = pd.Series(X['day_word'].unique()).sort_values().values, index = X.index)\n",
    "\n",
    "# combine features and remove duplicate features\n",
    "X = pd.concat([X, scaler_df, encoder_df, encoder_df2, encoder_df3], axis=1)\n",
    "X = X[[0, 'is_whole_number', 'is_holiday', 'is_weekend', 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, \"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"sunday\"]]\n",
    "X.rename({0: \"amount (standardized)\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83312d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92b613e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 7, 2, ..., 2, 0, 7])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "lr = LogisticRegression(multi_class = \"multinomial\").fit(X_train, y_train)\n",
    "y_train = le.transform(y_train)\n",
    "rr = Ridge(alpha = 1).fit(X_train, y_train)\n",
    "# sgd = SGDClassifier(loss=\"log\").fit(X_train, y_train)\n",
    "\n",
    "# predict and store predictions\n",
    "lr_preds = le.transform(lr.predict(X_test))\n",
    "# sgd_preds = sgd.predict(X_test)\n",
    "\n",
    "y_test = np.array(y_test['new_category'])\n",
    "y_test_encoded = le.transform(y_test)\n",
    "y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42947c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101417    1.754446\n",
       "152365    1.756610\n",
       "109641    2.285188\n",
       "29174     2.287831\n",
       "144643    2.287851\n",
       "            ...   \n",
       "111460    2.643557\n",
       "61629     2.643758\n",
       "128326    2.645205\n",
       "146273    2.810262\n",
       "40496     4.546615\n",
       "Length: 163714, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_preds = rr.predict(X_test)\n",
    "pd.Series(rr_preds).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c2220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_accuracy = (lr_preds == y_test_encoded).mean()\n",
    "# sgd_accuracy = (sgd_preds == y_test_encoded).mean()\n",
    "print(\"Logistic Regression accuracy: {}, \\nSGDClassifier accuracy: {}\".format(lr_accuracy, sgd_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2083e3",
   "metadata": {},
   "source": [
    "# Part 3: Composite Model\n",
    "##### Kyle using Logistic Regression to combine the probabilities from each class from both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3a7931d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_proba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bg/tjm2hhbn7vl_j003610q1dnc0000gn/T/ipykernel_4574/449455407.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfidf_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrr_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lr_proba' is not defined"
     ]
    }
   ],
   "source": [
    "tfidf_proba, lr_proba, rr_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96882d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lr_proba = lr.predict_proba(X_test)\n",
    "# # final_model = LogisticRegression().fit()\n",
    "# for weight in range(0,20): # learn weight\n",
    "#     weighted_average = nontext_proba + weight*tfidf_proba\n",
    "#     final_df = pd.DataFrame(weighted_average)\n",
    "# # todo: do a sanity check on this model. look at a specific transaction and trace it\n",
    "#     final_model = LogisticRegression().fit(final_df, y_test)\n",
    "    \n",
    "#     preds = final_model.predict(final_df)\n",
    "#     print(weight, np.mean(preds == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dae507fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPOSITE MODEL DOES NOT WORK\n",
    "# next week:\n",
    "# -kyle: think about trying ridge regression\n",
    "# -try to combine the X_train non-text and text data rather than combining the predictions\n",
    "# -both text and non-text were already trained on LR so shouldn't be too difficult\n",
    "# -might have to take it out of the pipeline\n",
    "# -start working on bert and gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b6356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
